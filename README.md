# My Learning Notes on the book "Build a Large Language Model (From Scratch)" by Professor Raschka

## Introduction
- My Greatest Thanks to Professor Raschka, the author of this book.
- I am using a MacBook Air A1466 from 2015. It installed PyTorch version 2.2.2 for Intel macOS. My laptop does not have a compatible GPU, and it does not have an Apple Silicon chip.
- I am using "The Pit and the Pendulum" by Edgar Allan Poe (which is in the public domain) instead of "The Verdict" to get some novel results in Chapter 2, Chapter 5, and Appendix D.
- I am using the UCI Sentiment Labelled Sentences dataset instead of the UCI SMS Spam Collection dataset to get some novel results in Chapter 6 and Appendix E.

## My Current Progress
- ‚úÖ Set Up (Using uv)
- ‚úÖ Chapter 1: Understanding LLM
- ‚úÖ Appendix A: Introduction to PyTorch
- ‚úÖ Chapter 2: Planning + Preparing Text
- ‚úÖ Chapter 3: Attention Mechanism
- ‚úÖ Chapter 4: Coding a LLM
- ‚úÖ Chapter 5: LLM Pretraining
- ‚úÖ Chapter 6: Classification Fine-tuning
- ‚úÖ Chapter 7: Instruction Fune-tuning
- üß† Appendix D: Enhance the Training Function
- ‚è≥ Appendix E: Fune-tuning with LoRA
- ‚è≥ Selected Bonus Materials

## Useful Links
- [The Official GitHub Repository of this Book](https://github.com/rasbt/LLMs-from-scratch)
- The Author's Blog: [Link-1](https://magazine.sebastianraschka.com/), [Link-2](https://sebastianraschka.com/blog/)
- [The Author's Free Courses](https://sebastianraschka.com/teaching/)
- [All Bonus Material](https://github.com/rasbt/LLMs-from-scratch?tab=readme-ov-file#bonus-material)
- [Explore Recent Research Papers](https://arxiv.org/list/cs.LG/recent)
