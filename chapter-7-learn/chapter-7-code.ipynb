{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "714353dd",
   "metadata": {},
   "source": [
    "# 7.2 Preparing a dataset for supervised instruction fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be7cad20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function for downloading the dataset\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        text_data = response.text\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0387113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "# Downloading the dataset\n",
    "file_path = \"instruction-data.json\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5edf212f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Evaluate the following phrase by transforming it into the spelling given.', 'input': 'freind --> friend', 'output': 'The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".'}\n"
     ]
    }
   ],
   "source": [
    "# Print one entry\n",
    "print(\"Example entry:\\n\", data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aabb2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another example entry:\n",
      " {'instruction': 'Convert 45 kilometers to meters.', 'input': '', 'output': '45 kilometers is 45000 meters.'}\n"
     ]
    }
   ],
   "source": [
    "# Print another entry without input\n",
    "print(\"Another example entry:\\n\", data[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc643fe3",
   "metadata": {},
   "source": [
    "## Exercise 7.1 - Page 209\n",
    "Since this exercise takes too long to train on my laptop, I decided not to finish it. According to the exercise solutions, this adjustment results in an equal performance with the current approach with a faster speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abc186b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the prompt formatting function\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd143c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Evaluate the following phrase by transforming it into the spelling given.\n",
      "\n",
      "### Input:\n",
      "freind --> friend\n",
      "\n",
      "### Response:\n",
      "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".\n"
     ]
    }
   ],
   "source": [
    "# Test it on an entry\n",
    "model_input = format_input(data[0])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[0]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6714d098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert 45 kilometers to meters.\n",
      "\n",
      "### Response:\n",
      "45 kilometers is 45000 meters.\n"
     ]
    }
   ],
   "source": [
    "# Test on an entry without input\n",
    "model_input = format_input(data[2])\n",
    "desired_response = f\"\\n\\n### Response:\\n{data[2]['output']}\"\n",
    "print(model_input + desired_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bad8e1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "# Partitioning the dataset\n",
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d15a6c5",
   "metadata": {},
   "source": [
    "# 7.3 Organizing data into training batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87a9dd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing an instruction dataset class\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(tokenizer.encode(full_text))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec10f203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "# Initialize tokenizer\n",
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special = {\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e78da4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cunstom collage function\n",
    "def custom_collate_draft_1(batch, pad_token_id = 50256, device = \"cpu\"):\n",
    "    batch_max_length = max(len(item) + 1 for item in batch)\n",
    "    inputs_list = []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_list.append(inputs)\n",
    "    inputs_tensor = torch.stack(inputs_list).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af390847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "# Test with three different inputs\n",
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "batch = (inputs_1, inputs_2, inputs_3)\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2607e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updating the collate function to generate the target token IDs\n",
    "def custom_collate_draft_2(batch, pad_token_id = 50256, device = \"cpu\"):\n",
    "    batch_max_length = max(len(item) + 1 for item in batch)\n",
    "    inputs_list, targets_list = [], []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        inputs_list.append(inputs)\n",
    "        targets_list.append(targets)\n",
    "    inputs_tensor = torch.stack(inputs_list).to(device)\n",
    "    targets_tensor = torch.stack(targets_list).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d16b817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "# Test the above function\n",
    "inputs, targets = custom_collate_draft_2(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76936d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a custom batch collage function (final version)\n",
    "def custom_collate_fn(batch, pad_token_id=50256, ignore_index=-100, allowed_max_length=None, device=\"cpu\"):\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddb91092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "# Test the collate function\n",
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50561056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n"
     ]
    }
   ],
   "source": [
    "# Explore the reason behind token replacement of -100\n",
    "logits_1 = torch.tensor([[-1.0, 1.0], [-0.5, 1.5]])\n",
    "targets_1 = torch.tensor([0, 1])\n",
    "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
    "print(loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da097b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7936)\n"
     ]
    }
   ],
   "source": [
    "# Adding an additional token ID affects the loss calculation\n",
    "logits_2 = torch.tensor([[-1.0, 1.0], [-0.5, 1.5], [-0.5, 1.5]])\n",
    "targets_2 = torch.tensor([0, 1, 1])\n",
    "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
    "print(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af64e6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1269)\n",
      "loss_1 == loss_3: tensor(True)\n"
     ]
    }
   ],
   "source": [
    "# Replace the third target token ID with -100\n",
    "targets_3 = torch.tensor([0, 1, -100])\n",
    "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
    "print(loss_3)\n",
    "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724ab929",
   "metadata": {},
   "source": [
    "## Exercise 7.2 - Page 223\n",
    "Since this exercise takes too long to train on my laptop, I decided not to finish it. According to the exercise solutions, this adjustment results in a slightly worse performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8859a366",
   "metadata": {},
   "source": [
    "# 7.4 Creating data loaders for an instruction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07d4c6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# initializes the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b810c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefill the device function\n",
    "from functools import partial\n",
    "customized_collate_fn = partial(custom_collate_fn, device = device, allowed_max_length = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f02dec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the data loaders\n",
    "from torch.utils.data import DataLoader\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf630a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "# Examine the dimensions\n",
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d02840",
   "metadata": {},
   "source": [
    "# 7.5 Loading a pretrained LLM\n",
    "To speed up the fine-tuning process, I decided to use the smaller model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "903bdcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 10:19:34.149524: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: ../chapter-5-learn/gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: ../chapter-5-learn/gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: ../chapter-5-learn/gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: ../chapter-5-learn/gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: ../chapter-5-learn/gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: ../chapter-5-learn/gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: ../chapter-5-learn/gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "# Loading the pretrained model\n",
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"drop_rate\": 0.0,\n",
    "    \"qkv_bias\": True\n",
    "}\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"../chapter-5-learn/gpt2\")\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61f692de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "# Test on an example to see baseline\n",
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8c2f12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try on the above example\n",
    "from previous_chapters import generate, text_to_token_ids, token_ids_to_text\n",
    "token_ids = generate(model = model, idx = text_to_token_ids(input_text, tokenizer),\n",
    "                     max_new_tokens=35, context_size=BASE_CONFIG[\"context_length\"], eos_id=50256)\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa611914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active\n"
     ]
    }
   ],
   "source": [
    "# isolate the model's repsonse text\n",
    "response_text = generated_text[len(input_text):].strip()\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fc5d1d",
   "metadata": {},
   "source": [
    "# 7.6 Fine-tuning the LLM on instruction data\n",
    "I will only train one epoch to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4168bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.167123317718506\n",
      "Validation loss: 4.050918436050415\n"
     ]
    }
   ],
   "source": [
    "# DO NOT RUN AGAIN - TAKES TOO LONG\n",
    "# Prepare for training and calculate the initial loss\n",
    "from previous_chapters import calc_loss_loader, train_model_simple\n",
    "model.to(device)\n",
    "torch.manual_seed(123)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e876239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 3.119, Val loss 3.069\n",
      "Ep 1 (Step 000005): Train loss 1.696, Val loss 1.570\n",
      "Ep 1 (Step 000010): Train loss 1.096, Val loss 1.164\n",
      "Ep 1 (Step 000015): Train loss 1.053, Val loss 1.083\n",
      "Ep 1 (Step 000020): Train loss 0.970, Val loss 1.038\n",
      "Ep 1 (Step 000025): Train loss 0.919, Val loss 1.002\n",
      "Ep 1 (Step 000030): Train loss 0.960, Val loss 0.978\n",
      "Ep 1 (Step 000035): Train loss 0.877, Val loss 0.951\n",
      "Ep 1 (Step 000040): Train loss 0.847, Val loss 0.943\n",
      "Ep 1 (Step 000045): Train loss 0.777, Val loss 0.925\n",
      "Ep 1 (Step 000050): Train loss 0.869, Val loss 0.911\n",
      "Ep 1 (Step 000055): Train loss 0.923, Val loss 0.893\n",
      "Ep 1 (Step 000060): Train loss 0.872, Val loss 0.877\n",
      "Ep 1 (Step 000065): Train loss 0.800, Val loss 0.867\n",
      "Ep 1 (Step 000070): Train loss 0.694, Val loss 0.860\n",
      "Ep 1 (Step 000075): Train loss 0.706, Val loss 0.855\n",
      "Ep 1 (Step 000080): Train loss 0.753, Val loss 0.847\n",
      "Ep 1 (Step 000085): Train loss 0.680, Val loss 0.836\n",
      "Ep 1 (Step 000090): Train loss 0.729, Val loss 0.827\n",
      "Ep 1 (Step 000095): Train loss 0.652, Val loss 0.821\n",
      "Ep 1 (Step 000100): Train loss 0.634, Val loss 0.808\n",
      "Ep 1 (Step 000105): Train loss 0.728, Val loss 0.803\n",
      "Ep 1 (Step 000110): Train loss 0.718, Val loss 0.799\n",
      "Ep 1 (Step 000115): Train loss 0.672, Val loss 0.796\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Input: The following is a sentence.  ### Response\n",
      "Ep 2 (Step 000120): Train loss 0.591, Val loss 0.790\n",
      "Ep 2 (Step 000125): Train loss 0.625, Val loss 0.801\n",
      "Ep 2 (Step 000130): Train loss 0.583, Val loss 0.789\n",
      "Ep 2 (Step 000135): Train loss 0.546, Val loss 0.791\n",
      "Ep 2 (Step 000140): Train loss 0.579, Val loss 0.789\n",
      "Ep 2 (Step 000145): Train loss 0.518, Val loss 0.785\n",
      "Ep 2 (Step 000150): Train loss 0.520, Val loss 0.781\n",
      "Ep 2 (Step 000155): Train loss 0.594, Val loss 0.785\n",
      "Ep 2 (Step 000160): Train loss 0.585, Val loss 0.785\n",
      "Ep 2 (Step 000165): Train loss 0.537, Val loss 0.781\n",
      "Ep 2 (Step 000170): Train loss 0.440, Val loss 0.775\n",
      "Ep 2 (Step 000175): Train loss 0.479, Val loss 0.769\n",
      "Ep 2 (Step 000180): Train loss 0.540, Val loss 0.760\n",
      "Ep 2 (Step 000185): Train loss 0.567, Val loss 0.757\n",
      "Ep 2 (Step 000190): Train loss 0.442, Val loss 0.742\n",
      "Ep 2 (Step 000195): Train loss 0.469, Val loss 0.729\n",
      "Ep 2 (Step 000200): Train loss 0.408, Val loss 0.728\n",
      "Ep 2 (Step 000205): Train loss 0.480, Val loss 0.724\n",
      "Ep 2 (Step 000210): Train loss 0.516, Val loss 0.725\n",
      "Ep 2 (Step 000215): Train loss 0.539, Val loss 0.734\n",
      "Ep 2 (Step 000220): Train loss 0.413, Val loss 0.738\n",
      "Ep 2 (Step 000225): Train loss 0.487, Val loss 0.738\n",
      "Ep 2 (Step 000230): Train loss 0.425, Val loss 0.742\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Input: What is the chemical symbol for carbon?  \n",
      "Training completed in 46.84 minutes.\n"
     ]
    }
   ],
   "source": [
    "# DO NOT RUN AGAIN - TAKES TOO LONG\n",
    "# Instruction fine-tuning the pre-trained LLM\n",
    "import time\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "num_epochs = 2\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c43d1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DO NOT RUN AGAIN - TAKES TOO LONG\n",
    "# Examine the training and validation loss curves\n",
    "from previous_chapters import plot_losses\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ec5cc1",
   "metadata": {},
   "source": [
    "## Exercise 7.3 - Page 233\n",
    "Since this exercise will take too long and require GPU, I decided to skip it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8718dd46",
   "metadata": {},
   "source": [
    "# 7.7 Extracting and saving responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c9d19c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a horse.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> The type of cloud typically associated with thunderstorms is a tropical rainforest.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Robert Frost.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print model responses alongside the expected test set answers\n",
    "torch.manual_seed(123)\n",
    "for entry in test_data[:3]:\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(model = model, idx = text_to_token_ids(input_text, tokenizer),\n",
    "                         max_new_tokens = 256, context_size = BASE_CONFIG[\"context_length\"], eos_id = 50256)\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "508c240f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 110/110 [12:23<00:00,  6.76s/it]\n"
     ]
    }
   ],
   "source": [
    "# Generating test set responses\n",
    "from tqdm import tqdm\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8307cfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a horse.'}\n"
     ]
    }
   ],
   "source": [
    "# Verify using a sample\n",
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b443c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as gpt2-small124M-sft.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the model for future use\n",
    "import re\n",
    "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
    "torch.save(model.state_dict(), file_name)\n",
    "print(f\"Model saved as {file_name}\")\n",
    "# Load model via model.load_state_dict(torch.load(\"gpt2-small124M-sft.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04334371",
   "metadata": {},
   "source": [
    "# 7.8 Evaluating the fine-tuned LLM\n",
    "For section 7.8 and other exercises, please check the section-7-8-code.ipynb file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Learning-Notes_LLM-from-Scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
